{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d271c5c-46e6-4f07-9a5d-c10841de937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ab113-8151-423b-b1a3-54ffb6d76269",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb03daf5-d972-40a5-9ebd-0ffff40c2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc869e0-3d2b-489f-abfc-6da7071cc811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crisi/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/crisi/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True) #开启预训练，迁移参数\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1]) #最后一层不要\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85306b07-67cf-4ef1-b06c-cc9a71126d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "def pre_process_image(img_path):\n",
    "    image = Image.open(img_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # 添加batch维度，移动到GPU\n",
    "    return preprocess(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fe6ba0-cf03-404e-ae1c-40957713af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建标签图像\n",
    "def create_label_image(json_path, img_shape):\n",
    "    with open(json_path, 'r') as f:\n",
    "        label_data = json.load(f)\n",
    "    \n",
    "    label_image = np.zeros((img_shape[0], img_shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    for shape in label_data['shapes']:\n",
    "        label_name = shape['label']  # 获取标签名称\n",
    "        points = np.array(shape['points'], dtype=np.int32)  # 获取多边形顶点\n",
    "        \n",
    "        # 绘制标签区域\n",
    "        if label_name == 'road':  # 假设\"road\"对应标签1\n",
    "            cv2.fillPoly(label_image, [points], 1)\n",
    "        elif label_name == 'building':  # 假设\"building\"对应标签2\n",
    "            cv2.fillPoly(label_image, [points], 2)\n",
    "    \n",
    "    return label_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7362dbce-1c19-42f7-a41d-a6e9e2a884c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据，提取特征和标签\n",
    "class RoadSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_paths, json_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.json_paths = json_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        json_path = self.json_paths[idx]\n",
    "\n",
    "        # 加载图像和标签\n",
    "        img = cv2.imread(img_path)\n",
    "        labels = create_label_image(json_path, img.shape)\n",
    "\n",
    "        # 图像预处理\n",
    "        image_tensor = pre_process_image(img_path)\n",
    "\n",
    "        # 使用ResNet18提取特征\n",
    "        with torch.no_grad():\n",
    "            features = model(image_tensor)\n",
    "\n",
    "        features_up = features.cpu().numpy().flatten()  # 展平为1D向量\n",
    "        labels = labels.flatten()  # 展平标签\n",
    "\n",
    "        return features_up, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb950aad-cc4f-478b-bb7d-edbc8f40bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 1\n",
    "data_names = ['0618', '0854', '1066']\n",
    "data_name = data_names[target - 1]\n",
    "\n",
    "image_path = f'../input_data/{data_name}.png'\n",
    "labels_path = f'../input_data/{data_name}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b0d794-524d-4a62-9f11-e220b4f52bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ./Features/0618_resnet_features.npy\n",
      "(1, 512)\n",
      "Labels saved to ./Features/0618_resnet_labels.npy\n",
      "(1, 125000)\n"
     ]
    }
   ],
   "source": [
    "# 创建数据集\n",
    "dataset = RoadSegmentationDataset([image_path], [labels_path])\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 提取特征和标签并保存\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "for features, labels in dataloader:\n",
    "    features_list.append(features)\n",
    "    labels_list.append(labels)\n",
    "\n",
    "features_up = np.concatenate(features_list, axis=0)\n",
    "labels_up = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "save_path = f'./Features/{data_name}_resnet_features.npy'\n",
    "np.save(save_path, features_up)\n",
    "print(f'Features saved to {save_path}')\n",
    "print(features_up.shape)\n",
    "\n",
    "label_save_path = f'./Features/{data_name}_resnet_labels.npy'\n",
    "np.save(label_save_path, labels_up)\n",
    "print(f'Labels saved to {label_save_path}')\n",
    "print(labels_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1096024-ba29-4c70-816e-083a7b99e455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
