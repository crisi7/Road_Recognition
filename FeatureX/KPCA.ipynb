{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb7abe0-5d10-4f43-954b-28f62bd5dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "840cd3ae-28c4-4676-8fbd-b0d54d2e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择图片和标签数据\n",
    "target = 1\n",
    "data_name = ['0618', '0854', '1066'][target - 1]\n",
    "img_path = f'../input_data/{data_name}.png'  # 原图路径\n",
    "output_features_filename = f'./Features/{data_name}_KPCA_features.npy'  # 数据输出路径\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "image = img.reshape(-1, 3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_tensor = torch.tensor(image, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a587caae-9e59-4a18-b098-0d48bb09b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = image_tensor.mean(dim=0)\n",
    "std = image_tensor.std(dim=0)\n",
    "image_tensor_scaled = (image_tensor - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb49feeb-1f14-44f5-b28c-0326e2833866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X, gamma=1.0):\n",
    "    sq_dists = torch.cdist(X, X, p=2)**2\n",
    "    return torch.exp(-gamma * sq_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "324a45b4-468c-4dd8-bb94-6e4d42fe44ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 58.21 GiB. GPU 0 has a total capacity of 6.00 GiB of which 4.98 GiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 10.49 MiB is allocated by PyTorch, and 11.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43mrbf_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_tensor_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m N \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m one_N \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(N, N)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;241m/\u001b[39m N\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[0;34m(X, gamma)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrbf_kernel\u001b[39m(X, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     sq_dists \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mgamma \u001b[38;5;241m*\u001b[39m sq_dists)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/functional.py:1336\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1334\u001b[0m         cdist, (x1, x2), x1, x2, p\u001b[38;5;241m=\u001b[39mp, compute_mode\u001b[38;5;241m=\u001b[39mcompute_mode)\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mm_for_euclid_dist_if_necessary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compute_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mm_for_euclid_dist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mcdist(x1, x2, p, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 58.21 GiB. GPU 0 has a total capacity of 6.00 GiB of which 4.98 GiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 10.49 MiB is allocated by PyTorch, and 11.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "gamma = 10\n",
    "K = rbf_kernel(image_tensor_scaled, gamma)\n",
    "\n",
    "N = K.size(0)\n",
    "one_N = torch.ones(N, N).to(device) / N\n",
    "K_centered = K - torch.matmul(one_N, K) - torch.matmul(K, one_N) \\\n",
    "            + torch.matmul(one_N, K, one_N)\n",
    "\n",
    "eigvals, eigvecs = torch.linalg.eig(K_centered)\n",
    "\n",
    "eigcals_sorted, indices = torch.sort(eigvals, descending=True)\n",
    "top_n_eigvals = eigvals[:, indices[:,2]].real\n",
    "\n",
    "X_kpca = torch.matmul(K_centered, top_n_eigvals)\n",
    "\n",
    "print(X_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344cb12-c02c-4e38-bb7f-84b27b9ca1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
